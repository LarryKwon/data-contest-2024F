{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICAIF 2024 금융-RAG 챌린지 기본 예제\n",
    "\n",
    "이 노트북은 **ICAIF 2024 금융-RAG 챌린지**를 위한 **기본 예제**입니다. 이 챌린지의 목표는 금융 데이터를 위한 **Retrieval-Augmented Generation (RAG)** 시스템을 만드는 것입니다. 참가자는 대규모 코퍼스에서 관련 문서를 검색하고 사용자 Query에 대한 정확하고 상황에 맞는 응답을 제공하는 시스템을 개발해야 합니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 시스템 구성 요소\n",
    "\n",
    "기본 예제의 시스템은 두 가지 주요 구성 요소로 나뉩니다:\n",
    "\n",
    "1. **검색**: 사용자 쿼리를 기반으로 대규모 금융 문서 코퍼스에서 관련 문서를 검색합니다.\n",
    "2. **재정렬**: 검색된 문서의 순위를 다시 매겨 가장 관련성 높은 정보가 우선되도록 합니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 모델 개요\n",
    "\n",
    "이 베이스라인 노트북은 `SentenceTransformer`와 `CrossEncoder` 모델을 조합하여 다음 작업을 수행합니다:\n",
    "\n",
    "- **검색 모델**은 쿼리와 문서를 임베딩으로 인코딩하는 역할을 담당합니다.\n",
    "- **재정렬 모델**은 검색된 문서의 관련성을 평가하고 순서를 조정합니다.\n",
    "\n",
    "이 예시에서는 **FinDER**라는 FinanceRAG 프로젝트의 7개 과제 중 하나를 사용합니다. 검색 모델로는 `intfloat/e5-large-v2`가 사용되며, 재정렬은 `cross-encoder/ms-marco-MiniLM-L-12-v2`를 통해 수행됩니다. 두 모델 모두 `sentence_transformers` 라이브러리에서 지원하는 다른 모델로 대체하여 성능을 실험해볼 수 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 목표\n",
    "\n",
    "이 노트북의 목표는 참가자들이 챌린지를 위한 보다 **고급 솔루션**을 구축할 수 있는 **탄탄한 기반**을 제공하는 것입니다. 과제, 검색 모델 및 재정렬 모델을 필요에 따라 자유롭게 개발하세요!\n",
    "\n",
    "---\n",
    "\n",
    "## Repository Setup and Environment Configuration\n",
    "\n",
    "GitHub 리포지토리 확인 [here](https://github.com/linq-rag/FinanceRAG).\n",
    "\n",
    "아래와 같이 Github repository를 Clone하기:\n",
    "\n",
    "### 1. Clone the repository:\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/linq-rag/FinanceRAG.git\n",
    "cd FinanceRAG\n",
    "```\n",
    "\n",
    "### 2. Set up the Python environment:\n",
    "\n",
    "#### If using `venv` (Python 3.11 or higher required):\n",
    "\n",
    "```bash\n",
    "python3 -m venv .venv\n",
    "source .venv/bin/activate  # On Windows use .venv\\Scripts\u0007ctivate\n",
    "pip install --upgrade pip\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "#### If using `conda`:\n",
    "\n",
    "```bash\n",
    "conda create -n financerag python=3.11\n",
    "conda activate financerag\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "준비가 완료되었습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:50:33.702172Z",
     "iopub.status.busy": "2024-10-04T14:50:33.701317Z",
     "iopub.status.idle": "2024-10-04T14:51:15.803357Z",
     "shell.execute_reply": "2024-10-04T14:51:15.802271Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "# --------------------------------------\n",
    "# Import required libraries for document retrieval, reranking, and logging setup.\n",
    "from sentence_transformers import CrossEncoder\n",
    "import logging\n",
    "\n",
    "from financerag.rerank import CrossEncoderReranker\n",
    "from financerag.retrieval import DenseRetrieval, SentenceTransformerEncoder\n",
    "from financerag.tasks import FinDER\n",
    "\n",
    "# Setup basic logging configuration to show info level messages.\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:51:15.808338Z",
     "iopub.status.busy": "2024-10-04T14:51:15.807849Z",
     "iopub.status.idle": "2024-10-04T14:51:23.956758Z",
     "shell.execute_reply": "2024-10-04T14:51:23.955721Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: Initialize FinDER Task\n",
    "# --------------------------\n",
    "# In this baseline example, we are using the FinDER task, one of the seven available tasks in this project.\n",
    "# If you want to use a different task, for example, 'OtherTask', you can change the task initialization as follows:\n",
    "#\n",
    "# Example:\n",
    "# from financerag.tasks import OtherTask\n",
    "# finder_task = OtherTask()\n",
    "#\n",
    "# For this baseline, we proceed with FinDER.\n",
    "finder_task = FinDER()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:51:23.961016Z",
     "iopub.status.busy": "2024-10-04T14:51:23.960728Z",
     "iopub.status.idle": "2024-10-04T14:51:39.063618Z",
     "shell.execute_reply": "2024-10-04T14:51:39.062302Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: Initialize DenseRetriever model\n",
    "# -------------------------------------\n",
    "# Initialize the retrieval model using SentenceTransformers. This model will be responsible\n",
    "# for encoding both the queries and documents into embeddings.\n",
    "#\n",
    "# You can replace 'intfloat/e5-large-v2' with any other model supported by SentenceTransformers.\n",
    "# For example: 'BAAI/bge-large-en-v1.5', 'Linq-AI-Research/Linq-Embed-Mistral', etc.\n",
    "encoder_model = SentenceTransformerEncoder(\n",
    "    model_name_or_path='intfloat/e5-large-v2',\n",
    "    query_prompt='query: ',\n",
    "    doc_prompt='passage: ',\n",
    ")\n",
    "\n",
    "retrieval_model = DenseRetrieval(\n",
    "    model=encoder_model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:51:39.068549Z",
     "iopub.status.busy": "2024-10-04T14:51:39.068124Z",
     "iopub.status.idle": "2024-10-04T14:54:07.488228Z",
     "shell.execute_reply": "2024-10-04T14:54:07.486678Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 4: Perform retrieval\n",
    "# ---------------------\n",
    "# Use the model to retrieve relevant documents for given queries.\n",
    "retrieval_model = DenseRetrieval(\n",
    "    model=encoder_model\n",
    ")\n",
    "\n",
    "retrieval_result = finder_task.retrieve(\n",
    "    retriever=retrieval_model\n",
    ")\n",
    "\n",
    "# Print a portion of the retrieval results to verify the output.\n",
    "print(f\"Retrieved results for {len(retrieval_result)} queries. Here's an example of the top 5 documents for the first query:\")\n",
    "\n",
    "for q_id, result in retrieval_result.items():\n",
    "    print(f\"\\nQuery ID: {q_id}\")\n",
    "    # Sort the result to print the top 5 document ID and its score\n",
    "    sorted_results = sorted(result.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for i, (doc_id, score) in enumerate(sorted_results[:5]):\n",
    "        print(f\"  Document {i + 1}: Document ID = {doc_id}, Score = {score}\")\n",
    "\n",
    "    break  # Only show the first query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:54:07.495914Z",
     "iopub.status.busy": "2024-10-04T14:54:07.494072Z",
     "iopub.status.idle": "2024-10-04T14:54:09.186831Z",
     "shell.execute_reply": "2024-10-04T14:54:09.185722Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 5: Initialize CrossEncoder Reranker\n",
    "# --------------------------------------\n",
    "# The CrossEncoder model will be used to rerank the retrieved documents based on relevance.\n",
    "#\n",
    "# You can replace 'cross-encoder/ms-marco-MiniLM-L-12-v2' with any other model supported by CrossEncoder.\n",
    "# For example: 'cross-encoder/ms-marco-TinyBERT-L-2', 'cross-encoder/stsb-roberta-large', etc.\n",
    "reranker = CrossEncoderReranker(\n",
    "    model=CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:54:09.190909Z",
     "iopub.status.busy": "2024-10-04T14:54:09.190659Z",
     "iopub.status.idle": "2024-10-04T14:54:54.978852Z",
     "shell.execute_reply": "2024-10-04T14:54:54.977781Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 6: Perform reranking\n",
    "# -------------------------\n",
    "# Rerank the top 100 retrieved documents using the CrossEncoder model.\n",
    "reranking_result = finder_task.rerank(\n",
    "    reranker=reranker,\n",
    "    results=retrieval_result,\n",
    "    top_k=100,  # Rerank the top 100 documents\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Print a portion of the reranking results to verify the output.\n",
    "print(f\"Reranking results for {len(reranking_result)} queries. Here's an example of the top 5 documents for the first query:\")\n",
    "\n",
    "for q_id, result in reranking_result.items():\n",
    "    print(f\"\\nQuery ID: {q_id}\")\n",
    "    # Sort the result to print the top 5 document ID and its score\n",
    "    sorted_results = sorted(result.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for i, (doc_id, score) in enumerate(sorted_results[:5]):\n",
    "        print(f\"  Document {i + 1}: Document ID = {doc_id}, Score = {score}\")\n",
    "\n",
    "    break  # Only show the first query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:54:54.989320Z",
     "iopub.status.busy": "2024-10-04T14:54:54.989100Z",
     "iopub.status.idle": "2024-10-04T14:54:55.005455Z",
     "shell.execute_reply": "2024-10-04T14:54:55.004477Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 7: Save results\n",
    "# -------------------\n",
    "# Save the results to the specified output directory as a CSV file.\n",
    "output_dir = './results'\n",
    "finder_task.save_results(output_dir=output_dir)\n",
    "\n",
    "# Confirm the results have been saved.\n",
    "print(f\"Results have been saved to {output_dir}/FinDER/results.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9677683,
     "sourceId": 85594,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
